{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path found : ['A', 'B', 'D']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'D']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self,adjac_lis):\n",
    "        self.adjac_lis=adjac_lis\n",
    "    def get_neighbors(self,v):\n",
    "        return self.adjac_lis[v]\n",
    "    \n",
    "    def h(self,n):\n",
    "        H={\n",
    "            'A':1,\n",
    "            'B':1,\n",
    "            'C':1,\n",
    "            'D':1\n",
    "        }\n",
    "        \n",
    "        return H[n]\n",
    "    def a_star_algorithm(self,start,stop):\n",
    "        open_lst=set([start])\n",
    "        closed_lst=set([])\n",
    "        \n",
    "        poo={}\n",
    "        poo[start]=0\n",
    "        \n",
    "        par={}\n",
    "        par[start]=start\n",
    "        \n",
    "        while len(open_lst) >0 :\n",
    "            n=None\n",
    "            \n",
    "            for v in open_lst:\n",
    "                if n==None or poo[v]+self.h(v) < poo[n]+self.h(n):\n",
    "                    n=v\n",
    "            if n==None:\n",
    "                print('Path does not exist')\n",
    "                return None\n",
    "            \n",
    "            if n==stop:\n",
    "                reconst_path=[]\n",
    "                \n",
    "                while par[n]!=n:\n",
    "                    reconst_path.append(n)\n",
    "                    n=par[n]\n",
    "                reconst_path.append(start)\n",
    "                reconst_path.reverse()\n",
    "                \n",
    "                print('Path found : {}'.format(reconst_path))\n",
    "                return reconst_path\n",
    "            for (m,weight) in self.get_neighbors(n):\n",
    "                if m not in open_lst and m not in closed_lst:\n",
    "                    open_lst.add(m)\n",
    "                    par[m]=n\n",
    "                    \n",
    "                    poo[m]=poo[n]+weight\n",
    "                else:\n",
    "                    if poo[m]>poo[n]+weight:\n",
    "                        poo[m]=poo[n]+weight\n",
    "                        par[m]=n\n",
    "                        \n",
    "                        if m in closed_lst:\n",
    "                            closed_lst.remove(m)\n",
    "                            open_lst.add(m)\n",
    "            \n",
    "            open_lst.remove(n)\n",
    "            closed_lst.add(n)\n",
    "        print('Path does not exist!')\n",
    "        return None\n",
    "                        \n",
    "                    \n",
    "\n",
    "adjac_lis={\n",
    "    'A':[('B',1),('C',3),('D',7)],\n",
    "    'B':[('D',5)],\n",
    "    'C':[('D',12)]\n",
    "}\n",
    "\n",
    "graph1=Graph(adjac_lis)\n",
    "graph1.a_star_algorithm('A','D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A3\n",
      "\tHigh\n",
      "\t\tA1\n",
      "\t\t\tFalse\n",
      "\t\t\t\tA2\n",
      "\t\t\t\t\tCool-> ['No']\n",
      "\n",
      "\t\t\t\t\tHot-> ['Yes']\n",
      "\n",
      "\t\t\tTrue-> ['No']\n",
      "\n",
      "\tNormal-> ['Yes']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv('play.csv')\n",
    "features=[feat for feat in data]\n",
    "features.remove(\"classification\")\n",
    "\n",
    "class Node:\n",
    "    def __init__(self):\n",
    "        self.children=[]\n",
    "        self.value=\"\"\n",
    "        self.pred=\"\"\n",
    "        self.isLeaf=False\n",
    "def entropy(examples):\n",
    "    pos=0.0\n",
    "    neg=0.0\n",
    "    for _, row in examples.iterrows():\n",
    "        if row[\"classification\"] == \"Yes\":\n",
    "            pos += 1\n",
    "        else:\n",
    "            neg += 1\n",
    "    if pos == 0.0 or neg == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        p = pos / (pos + neg)\n",
    "        n = neg / (pos + neg)\n",
    "        return -(p * math.log(p, 2) + n * math.log(n, 2))\n",
    "def info_gain(examples,attr):\n",
    "    uniq=np.unique(examples[attr])\n",
    "    gain=entropy(examples)\n",
    "    \n",
    "    for u in uniq:\n",
    "        subdata=examples[examples[attr]==u]\n",
    "        sub_e=entropy(subdata)\n",
    "        \n",
    "        gain -=(float(len(subdata))/float(len(examples)))*sub_e\n",
    "        \n",
    "    return gain\n",
    "def ID3(examples,attrs):\n",
    "    root=Node()\n",
    "    \n",
    "    max_gain=0\n",
    "    max_feat=\"\"\n",
    "    \n",
    "    for feature in attrs:\n",
    "        gain=info_gain(examples,feature)\n",
    "        if gain > max_gain:\n",
    "            max_gain = gain\n",
    "            max_feat = feature\n",
    "    root.value=max_feat\n",
    "    uniq = np.unique(examples[max_feat])\n",
    "    #print (\"\\n\",uniq)\n",
    "    for u in uniq:\n",
    "        #print (\"\\n\",u)\n",
    "        subdata = examples[examples[max_feat] == u]\n",
    "        #print (\"\\n\",subdata)\n",
    "        if entropy(subdata) == 0.0:\n",
    "            newNode = Node()\n",
    "            newNode.isLeaf = True\n",
    "            newNode.value = u\n",
    "            newNode.pred = np.unique(subdata[\"classification\"])\n",
    "            root.children.append(newNode)\n",
    "        else:\n",
    "            dummyNode = Node()\n",
    "            dummyNode.value = u\n",
    "            new_attrs = attrs.copy()\n",
    "            new_attrs.remove(max_feat)\n",
    "            child = ID3(subdata, new_attrs)\n",
    "            dummyNode.children.append(child)\n",
    "            root.children.append(dummyNode)\n",
    "    return root\n",
    "        \n",
    "def printTree(root:Node,depth=0):\n",
    "    for i in range(depth):\n",
    "        print(\"\\t\",end=\"\")\n",
    "    print(root.value,end=\"\")\n",
    "    if root.isLeaf:\n",
    "        print(\"->\",root.pred)\n",
    "    print()\n",
    "    for child in root.children:\n",
    "        printTree(child,depth+1)\n",
    "root = ID3(data, features)\n",
    "printTree(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " [[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual output: \n",
      " [[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted output: \n",
      " [[0.89396357]\n",
      " [0.88236091]\n",
      " [0.89321533]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array(([2,9],[1,5],[3,6]),dtype=float)\n",
    "y=np.array(([92],[86],[89]),dtype=float)\n",
    "X=X/np.amax(X,axis=0)\n",
    "y=y/100\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "def derivative_sigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "epoch=7000\n",
    "lr=0.1\n",
    "inputlayer_neuron=2\n",
    "hiddenlayer_nueron=3\n",
    "output_neuron=1\n",
    "\n",
    "wh=np.random.uniform(size=(inputlayer_neuron,hiddenlayer_nueron))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_nueron))\n",
    "wout=np.random.uniform(size=(hiddenlayer_nueron,output_neuron))\n",
    "bout=np.random.uniform(size=(1,output_neuron))\n",
    "\n",
    "for i in range(epoch):\n",
    "    hinp1=np.dot(X,wh)\n",
    "    hinp=hinp1+bh\n",
    "    hlayer_act=sigmoid(hinp)\n",
    "    outinp1=np.dot(hlayer_act,wout)\n",
    "    outinp = outinp1+bout\n",
    "    output =sigmoid(outinp)\n",
    "    \n",
    "    \n",
    "    EO=y-output\n",
    "    outgrad=derivative_sigmoid(output)\n",
    "    d_output=EO*outgrad\n",
    "    \n",
    "    EH=d_output.dot(wout.T)\n",
    "    hiddengrad=derivative_sigmoid(hlayer_act)\n",
    "    d_hiddenlayer=EH*hiddengrad\n",
    "    \n",
    "    wout+= hlayer_act.T.dot(d_output) *lr\n",
    "    bout+=np.sum(d_output,axis=0,keepdims=True) *lr\n",
    "    wh+=X.T.dot(d_hiddenlayer) *lr\n",
    "    \n",
    "print(\"Input: \\n \"+str(X))\n",
    "print(\"Actual output: \\n\",str(y))\n",
    "print(\"Predicted output: \\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of dataset (2, 2)\n",
      "0    i love this sandwich\n",
      "1    i hate this sandwich\n",
      "Name: message, dtype: object\n",
      "0    1\n",
      "1    0\n",
      "Name: labelnum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "msg=pd.read_csv('bayes.csv',names=['message','label'])\n",
    "print(\"dimension of dataset\",msg.shape)\n",
    "msg['labelnum']=msg.label.map({'pos':1,'neg':0})\n",
    "\n",
    "X=msg.message\n",
    "Y=msg.labelnum\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy metrics\n",
      "Accuracy of the classifier is  0.0\n",
      "metrics confusion\n",
      "[[0 1]\n",
      " [0 0]]\n",
      "recall and precision\n",
      "0.0\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X,Y)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect=CountVectorizer()\n",
    "xtrain_dtm=count_vect.fit_transform(xtrain)\n",
    "xtest_dtm=count_vect.transform(xtest)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "elf=MultinomialNB().fit(xtrain_dtm,ytrain)\n",
    "predicted=elf.predict(xtest_dtm)\n",
    "from sklearn import metrics\n",
    "print('Accuracy metrics')\n",
    "print('Accuracy of the classifier is ',metrics.accuracy_score(ytest,predicted))\n",
    "print('metrics confusion')\n",
    "print(metrics.confusion_matrix(ytest,predicted))\n",
    "print('recall and precision')\n",
    "print(metrics.recall_score(ytest,predicted))\n",
    "print(metrics.precision_score(ytest,predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
